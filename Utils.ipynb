{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e96cca3-10b9-4f7c-b9b1-1864191bd3d0",
   "metadata": {},
   "source": [
    "#### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f94003e-fa48-42f4-9fd4-56bfeb333ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchio as tio\n",
    "\n",
    "def center_crop_brain(subject, target_size, z_offset=4):\n",
    "    \"\"\"\n",
    "    z_offset -> to remove layers near skull base\n",
    "    \"\"\"\n",
    "    from copy import deepcopy\n",
    "    import torch\n",
    "    #create brain mask\n",
    "    brain_mask = (subject['perf1'].data > 0).float()\n",
    "    \n",
    "    #get the x,y-coordinates of the center of the brain mask\n",
    "    z_mid = subject.spatial_shape[-1]//2\n",
    "    coordinates = torch.where(brain_mask[:,:,:,z_mid] > 0)\n",
    "    centers = [int(torch.round(coordinates[1].float().mean())), \n",
    "               int(torch.round(coordinates[2].float().mean())),]\n",
    "    \n",
    "    #create crop transform\n",
    "    start_x = max(0, centers[0]-(target_size[0]//2))\n",
    "    start_y = max(0, centers[1]-(target_size[1]//2))\n",
    "    start_z = max(0, z_mid - (target_size[2]//2 - z_offset))\n",
    "\n",
    "    stop_x = subject.spatial_shape[0] - (start_x+(target_size[0]))\n",
    "    stop_y = subject.spatial_shape[1] - (start_y+(target_size[1]))\n",
    "    stop_z = subject.spatial_shape[2] - (start_z+(target_size[2]))\n",
    "    \n",
    "    cropper = tio.Crop(cropping=(start_x, stop_x,\n",
    "                                 start_y, stop_y,\n",
    "                                 start_z, stop_z)\n",
    "                      )\n",
    "    \n",
    "    #apply cropping\n",
    "    cropped_subject = cropper(subject)\n",
    "    \n",
    "    return cropped_subject\n",
    "\n",
    "def preprocess(subject, target_size):\n",
    "    #define resampling parameters\n",
    "    if subject['perf1'].data.shape[1] == 256:\n",
    "        resample_x = 2\n",
    "        resample_y = 2\n",
    "    else:\n",
    "        resample_x = 2\n",
    "        resample_y = 2\n",
    "        \n",
    "    resample_z = subject['perf1'].spacing[-1] #do not resample in z-axis\n",
    "\n",
    "    #compose preprocessing w/o resizing\n",
    "    # # use Resample and CropOrPad to resize -> 'resizing: in most medical image applications, resizing shouldn't be\n",
    "    # # used as it will deform the physical object by scaling anisotropically along the different dimensions.\n",
    "    # # The solution is typically applying Resample and CropOrPad' ~TORCHIO\n",
    "    preprocess_tf = tio.Compose([\n",
    "        tio.transforms.ToCanonical(),\n",
    "        tio.transforms.Resample((resample_x, resample_y, resample_z)),\n",
    "        # tio.transforms.ZNormalization(), #Perf-Images of Kai are already normalized\n",
    "    ])\n",
    "\n",
    "    for perf in ['perf1']:#, 'perf2', 'perf3', 'perf4', 'perf5']:\n",
    "        subject[perf] = preprocess_tf(subject[perf])\n",
    "\n",
    "    #crop around center, z-offset depending on image size\n",
    "    if subject['perf1'].data.shape[-1] < 30:\n",
    "        subject_cropped = center_crop_brain(subject, target_size, z_offset=0)\n",
    "    else:\n",
    "        if subject['perf1'].data.shape[-1] < 34:\n",
    "            subject_cropped = center_crop_brain(subject, target_size, z_offset=2)\n",
    "        else:\n",
    "            subject_cropped = center_crop_brain(subject, target_size, z_offset=3)\n",
    "\n",
    "    return subject_cropped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dc08f4-6412-4a81-83ac-0a8f20b8e1ad",
   "metadata": {},
   "source": [
    "#### Dataset/Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548bd7da-ef60-40cf-836b-2fbd253f1267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "import torchio as tio\n",
    "import torch    \n",
    "from fastai.vision.all import *\n",
    "from fastai.data.core import DataLoaders\n",
    "\n",
    "def concatenate_subject_images(subject):\n",
    "    image_keys = [key for key, value in subject.items() if isinstance(value, tio.ScalarImage)]\n",
    "    image_tensors = [subject[key].data for key in image_keys]\n",
    "    concatenated_images = torch.cat(image_tensors, dim=0)\n",
    "    return concatenated_images\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, image_subjects, image_transform=None):\n",
    "        self.image_subjects = image_subjects\n",
    "        self.image_transform = image_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_subjects)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = concatenate_subject_images(self.image_subjects[index])\n",
    "        label = self.image_subjects[index]['target']\n",
    "        nihss = self.image_subjects[index]['nihss']\n",
    "        acc = self.image_subjects[index]['acc']\n",
    "        \n",
    "        # Apply transforms to subject       \n",
    "        if self.image_transform:\n",
    "            self.image_transform(image)\n",
    "        \n",
    "        return {\n",
    "            'image': image,\n",
    "            'label': label,\n",
    "            'nihss': nihss,\n",
    "            'acc': acc,\n",
    "        }\n",
    "\n",
    "def make_dls(train_subjects, valid_subjects, train_tf, valid_tf, train_bn=4, valid_bn=8):\n",
    "    \"\"\"Creates DataLoaders like FastAI with subjects (tio.subjects)\n",
    "    train_tf, valid_tf: Define transforms for training/validation set\n",
    "    train_bn, valid_bn: Training/validation batch size\n",
    "    test_size: ratio validation set\"\"\"\n",
    "\n",
    "    train_ds = Dataset(train_subjects, image_transform=train_tf)\n",
    "    valid_ds = Dataset(valid_subjects, image_transform=valid_tf)\n",
    "    \n",
    "    # Dataloader\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,                   \n",
    "        batch_size=train_bn,\n",
    "        shuffle=True,\n",
    "        drop_last=False,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    valid_loader = DataLoader(\n",
    "        valid_ds,\n",
    "        batch_size=valid_bn,\n",
    "        drop_last=False,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "        \n",
    "    # dls\n",
    "    dls = DataLoaders(train_loader, valid_loader)\n",
    "    return dls\n",
    "        \n",
    "def make_dls_img(subjects, train_tf, valid_tf, train_bn=4, valid_bn=8, test_size=0.2, random_state=42, test_set=False):\n",
    "    \"\"\"Creates DataLoaders like FastAI with subjects (tio.subjects)\n",
    "    train_tf, valid_tf: Define transforms for training/validation set\n",
    "    train_bn, valid_bn: Training/validation batch size\n",
    "    test_size: ratio validation set\"\"\"\n",
    "\n",
    "    if test_set:\n",
    "        train_ds = Dataset(subjects, image_transform=train_tf)\n",
    "        valid_ds = Dataset(subjects, image_transform=valid_tf)\n",
    "\n",
    "    else:\n",
    "        # Train/valid splits\n",
    "        train_subjects, valid_subjects = train_test_split(subjects,\n",
    "                                                          test_size=test_size,\n",
    "                                                          random_state=random_state)\n",
    "        # Datasets\n",
    "        train_ds = Dataset(train_subjects, image_transform=train_tf)\n",
    "        valid_ds = Dataset(valid_subjects, image_transform=valid_tf)\n",
    "    \n",
    "    # Dataloader\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,                   \n",
    "        batch_size=train_bn,\n",
    "        shuffle=True,\n",
    "        drop_last=False,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    valid_loader = DataLoader(\n",
    "        valid_ds,\n",
    "        batch_size=valid_bn,\n",
    "        drop_last=False,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "        \n",
    "    # dls\n",
    "    dls = DataLoaders(train_loader, valid_loader)\n",
    "    return dls\n",
    "\n",
    "# class CombinedDataset(Dataset):\n",
    "#     def __init__(self, image_subjects, tabular_data, image_transform=None):\n",
    "#         self.image_subjects = image_subjects\n",
    "#         self.tabular_data = tabular_data\n",
    "#         self.image_transform = image_transform\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.image_subjects)\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         image = self.image_subjects[index]['perf1'][tio.DATA]\n",
    "#         if type(self.tabular_data)==np.ndarray:\n",
    "#             tabular = self.tabular_data[index]\n",
    "#         else:\n",
    "#             tabular = self.tabular_data.loc[index].to_numpy()\n",
    "#         label = self.image_subjects[index]['target']\n",
    "#         nihss = self.image_subjects[index]['nihss']\n",
    "#         acc = self.image_subjects[index]['acc']\n",
    "        \n",
    "#         # Apply transforms to subject       \n",
    "#         if self.image_transform:\n",
    "#             self.image_transform(image)\n",
    "        \n",
    "#         return {\n",
    "#             'image': image,\n",
    "#             'tabular': tabular,\n",
    "#             'label': label,\n",
    "#             'nihss': nihss,\n",
    "#             'acc': acc,\n",
    "#         }\n",
    "\n",
    "# class Dataset(Dataset):\n",
    "#     def __init__(self, image_subjects, image_transform=None):\n",
    "#         self.image_subjects = image_subjects\n",
    "#         self.image_transform = image_transform\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.image_subjects)\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         image = self.image_subjects[index]['perf1'][tio.DATA]\n",
    "#         label = self.image_subjects[index]['target']\n",
    "#         nihss = self.image_subjects[index]['nihss']\n",
    "#         acc = self.image_subjects[index]['acc']\n",
    "        \n",
    "#         # Apply transforms to subject       \n",
    "#         if self.image_transform:\n",
    "#             self.image_transform(image)\n",
    "        \n",
    "#         return {\n",
    "#             'image': image,\n",
    "#             'label': label,\n",
    "#             'nihss': nihss,\n",
    "#             'acc': acc,\n",
    "#         }\n",
    "        \n",
    "def make_dls_img_and_tab(subjects, tabular, train_tf, valid_tf, train_bn=4, valid_bn=8, test_size=0.2, random_state=42, test_set=False):\n",
    "    \"\"\"Creates DataLoaders like FastAI with 1)subjects (tio.subjects) & 2)tabular data\n",
    "    train_tf, valid_tf: Define transforms for training/validation set\n",
    "    train_bn, valid_bn: Training/validation batch size\n",
    "    test_size: ratio validation set\"\"\"\n",
    "\n",
    "    if test_set:\n",
    "        train_ds = CombinedDataset(subjects, tabular, image_transform=train_tf)\n",
    "        valid_ds = CombinedDataset(subjects, tabular, image_transform=valid_tf)\n",
    "\n",
    "    else:\n",
    "        # Train/valid splits\n",
    "        train_subjects, valid_subjects, train_tab, valid_tab = train_test_split(subjects,\n",
    "                                                                            tabular,\n",
    "                                                                            test_size=test_size,\n",
    "                                                                            random_state=random_state)\n",
    "        # Datasets\n",
    "        train_ds = CombinedDataset(train_subjects, train_tab, image_transform=train_tf)\n",
    "        valid_ds = CombinedDataset(valid_subjects, valid_tab, image_transform=valid_tf)\n",
    "    \n",
    "    # Dataloader\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,                   \n",
    "        batch_size=train_bn,\n",
    "        shuffle=True,\n",
    "        drop_last=False,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    valid_loader = DataLoader(\n",
    "        valid_ds,\n",
    "        batch_size=valid_bn,\n",
    "        drop_last=False,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "        \n",
    "    # dls\n",
    "    dls = DataLoaders(train_loader, valid_loader)\n",
    "    return dls\n",
    "\n",
    "def make_dls_img(subjects, train_tf, valid_tf, train_bn=4, valid_bn=8, test_size=0.2, random_state=42, test_set=False):\n",
    "    \"\"\"Creates DataLoaders like FastAI with subjects (tio.subjects)\n",
    "    train_tf, valid_tf: Define transforms for training/validation set\n",
    "    train_bn, valid_bn: Training/validation batch size\n",
    "    test_size: ratio validation set\"\"\"\n",
    "\n",
    "    if test_set:\n",
    "        train_ds = Dataset(subjects, image_transform=train_tf)\n",
    "        valid_ds = Dataset(subjects, image_transform=valid_tf)\n",
    "\n",
    "    else:\n",
    "        # Train/valid splits\n",
    "        train_subjects, valid_subjects = train_test_split(subjects,\n",
    "                                                          test_size=test_size,\n",
    "                                                          random_state=random_state)\n",
    "        # Datasets\n",
    "        train_ds = Dataset(train_subjects, image_transform=train_tf)\n",
    "        valid_ds = Dataset(valid_subjects, image_transform=valid_tf)\n",
    "    \n",
    "    # Dataloader\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,                   \n",
    "        batch_size=train_bn,\n",
    "        shuffle=True,\n",
    "        drop_last=False,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    valid_loader = DataLoader(\n",
    "        valid_ds,\n",
    "        batch_size=valid_bn,\n",
    "        drop_last=False,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "        \n",
    "    # dls\n",
    "    dls = DataLoaders(train_loader, valid_loader)\n",
    "    return dls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8226b0f-78da-48f8-9c76-0910b5fc5b5f",
   "metadata": {},
   "source": [
    "#### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2734a6cd-7f94-4c8e-ad64-14a20eacd6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models.video import r3d_18\n",
    "\n",
    "#Building blocks\n",
    "class DAFT(nn.Module):\n",
    "    def __init__(self, in_channels, num_tabular_features):\n",
    "        super(DAFT, self).__init__()\n",
    "        self.auxiliary_network = nn.Sequential(\n",
    "            nn.Linear(num_tabular_features, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, in_channels * 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, tabular):\n",
    "        batch_size, channels, *spatial_dims = x.size()\n",
    "        params = self.auxiliary_network(tabular).view(batch_size, channels, 2)\n",
    "        scale, bias = params.split(1, dim=2)\n",
    "        return x * scale.view(batch_size, channels, *[1]*len(spatial_dims)) + \\\n",
    "               bias.view(batch_size, channels, *[1]*len(spatial_dims))\n",
    "\n",
    "class ResNet3D18(nn.Module):    \n",
    "    def __init__(self, num_classes, in_channels=1):\n",
    "        import torch\n",
    "        import torch.nn as nn\n",
    "        import torch.nn.functional as F\n",
    "        from torchvision.models.video import r3d_18\n",
    "        \n",
    "        super(ResNet3D18, self).__init__()\n",
    "        self.resnet = r3d_18(weights=False)\n",
    "        \n",
    "        self.resnet.stem[0] = nn.Conv3d(in_channels, 64, kernel_size=(3, 7, 7), \n",
    "                                        stride=(1, 2, 2), padding=(1, 3, 3), bias=False)\n",
    "        \n",
    "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "#Combined model for imaging and tabular data\n",
    "class CombinedModel_DAFT(nn.Module):\n",
    "    def __init__(self, num_classes, num_tabular_features, in_channels=3):\n",
    "        super(CombinedModel_DAFT, self).__init__()\n",
    "        self.resnet3d = ResNet3D18(num_classes, in_channels)\n",
    "        self.fc = nn.Linear(num_classes, num_classes)\n",
    "        \n",
    "        # Add DAFT modules\n",
    "        self.daft1 = DAFT(64, num_tabular_features)\n",
    "        self.daft2 = DAFT(128, num_tabular_features)\n",
    "        self.daft3 = DAFT(256, num_tabular_features)\n",
    "        self.daft4 = DAFT(512, num_tabular_features)\n",
    "    \n",
    "    def freeze_resnet(self, unfreeze_last_layer=True, unfreeze_last_conv_layers=2):\n",
    "        for param in self.resnet3d.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        if unfreeze_last_conv_layers > 0:\n",
    "            layers_to_unfreeze = list(self.resnet3d.resnet.layer4.children())[-unfreeze_last_conv_layers:]\n",
    "            for layer in layers_to_unfreeze:\n",
    "                for param in layer.parameters():\n",
    "                    param.requires_grad = True\n",
    "        \n",
    "        if unfreeze_last_layer:\n",
    "            for param in self.resnet3d.resnet.fc.parameters():\n",
    "                param.requires_grad = True\n",
    "    \n",
    "    def unfreeze_resnet(self):\n",
    "        for param in self.resnet3d.parameters():\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    def forward(self, image, tabular):\n",
    "        # Apply DAFT after each ResNet block\n",
    "        x = self.resnet3d.resnet.stem(image)\n",
    "        x = self.resnet3d.resnet.layer1(x)\n",
    "        x = self.daft1(x, tabular)\n",
    "        x = self.resnet3d.resnet.layer2(x)\n",
    "        x = self.daft2(x, tabular)\n",
    "        x = self.resnet3d.resnet.layer3(x)\n",
    "        x = self.daft3(x, tabular)\n",
    "        x = self.resnet3d.resnet.layer4(x)\n",
    "        x = self.daft4(x, tabular)\n",
    "        x = self.resnet3d.resnet.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        resnet_out = self.resnet3d.resnet.fc(x)\n",
    "        logits = self.fc(resnet_out)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44af1be7-ee54-41c5-9804-554a85cc512d",
   "metadata": {},
   "source": [
    "#### Learner/Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc9a1a9-cce7-4393-bd67-456d481b85c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from fastai.optimizer import Adam\n",
    "from fastai.basics import progress_bar, CancelFitException\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from fastai.imports import noop\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "class My_Learner_img_and_tab:\n",
    "    \"\"\"Learner for combined image and tabular data.\"\"\"\n",
    "    \n",
    "    np = __import__('numpy')\n",
    "    from fastai.optimizer import Adam\n",
    "    \n",
    "    def __init__(self, model, dls, loss_func, lr, cbs, opt_func=Adam):\n",
    "        store_attr()\n",
    "        for cb in cbs: cb.learner = self\n",
    "\n",
    "    def one_batch(self):\n",
    "        import torch\n",
    "        self('before_batch')\n",
    "        \n",
    "        if self.model.training:\n",
    "            images = self.batch['image'].float().cuda()\n",
    "            tabular = self.batch['tabular'].float().cuda()\n",
    "            yb = self.batch['label'].cuda()\n",
    "\n",
    "            self.preds = self.model(images, tabular)\n",
    "            self.loss = self.loss_func(self.preds, yb)\n",
    "            self.loss.backward()\n",
    "            self.opt.step()\n",
    "        \n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                images = self.batch['image'].float().cuda()\n",
    "                tabular = self.batch['tabular'].float().cuda()\n",
    "                yb = self.batch['label'].cuda()\n",
    "\n",
    "                self.preds = self.model(images, tabular)\n",
    "                self.loss = self.loss_func(self.preds, yb)\n",
    "                \n",
    "        acc = (self.preds.argmax(dim=1) == yb).float().sum()\n",
    "        self.accs.append(acc)\n",
    "        n = len(yb)\n",
    "        \n",
    "        self.losses.append(self.loss * n)\n",
    "        self.ns.append(n)\n",
    "        self.y_pred.append(self.preds.argmax(dim=1).cpu())\n",
    "        self.y_true.append(yb.cpu())\n",
    "        self('after_batch')\n",
    "\n",
    "    def one_epoch(self, train):\n",
    "        from fastai.basics import progress_bar\n",
    "        self.model.training = train\n",
    "        self('before_epoch')\n",
    "        self.accs, self.losses, self.ns, self.y_pred, self.y_true = [], [], [], [], []\n",
    "        \n",
    "        dl = self.dls.train if train else self.dls.valid\n",
    "        for self.num, self.batch in enumerate(progress_bar(dl, leave=False)):\n",
    "            self.one_batch()\n",
    "        \n",
    "        n = sum(self.ns)\n",
    "        y_true = torch.cat(self.y_true).numpy()\n",
    "        y_pred = torch.cat(self.y_pred).numpy()\n",
    "        f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "        \n",
    "        phase = \"TRAINING\" if self.model.training else \"VALIDATION\"\n",
    "        print(f'{\"Epoch: \" + str(self.epoch) if self.model.training else \"\"}')\n",
    "        print(f'{phase} Loss: {sum(self.losses).item()/n:.4f}, Accuracy: {sum(self.accs).item()/n:.4f}, F1-score: {f1:.4f}')\n",
    "        \n",
    "        if self.model.training: \n",
    "            self.tr_losses_acc.append(sum(self.losses).item()/n)\n",
    "            self.tr_f1_scores.append(f1)\n",
    "        else: \n",
    "            self.va_losses_acc.append(sum(self.losses).item()/n)\n",
    "            self.va_f1_scores.append(f1)\n",
    "            print('----------------------------------------------------------')\n",
    "        self('after_epoch')\n",
    "    \n",
    "    def fit(self, n_epochs):\n",
    "        from fastai.basics import CancelFitException\n",
    "        from fastai.basics import progress_bar\n",
    "        import torch\n",
    "        self('before_fit')\n",
    "        self.tr_losses_acc, self.va_losses_acc = [], []\n",
    "        self.tr_f1_scores, self.va_f1_scores = [], []\n",
    "        \n",
    "        self.model = self.model.float().cuda()\n",
    "    \n",
    "        self.opt = self.opt_func(self.model.parameters(), self.lr)\n",
    "        self.n_epochs = n_epochs\n",
    "        try:\n",
    "            for self.epoch in progress_bar(range(n_epochs)):\n",
    "                self.one_epoch(True)\n",
    "                self.one_epoch(False)\n",
    "        except CancelFitException: pass\n",
    "        self('after_fit')\n",
    "        \n",
    "    def validate(self):\n",
    "        self.one_epoch(False)\n",
    "        \n",
    "        import matplotlib.pyplot as plt\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        ax1.plot(self.tr_losses_acc, label='Training')\n",
    "        ax1.plot(self.va_losses_acc, label='Validation')\n",
    "        ax1.set_title('Loss')\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.set_yscale('log')\n",
    "        ax1.legend()\n",
    "        \n",
    "        ax2.plot(self.tr_f1_scores, label='Training')\n",
    "        ax2.plot(self.va_f1_scores, label='Validation')\n",
    "        ax2.set_title('F1-score')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_ylabel('F1-score')\n",
    "        ax2.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        self('after_fit')\n",
    "        \n",
    "    def __call__(self, name):\n",
    "        from fastai.imports import noop\n",
    "        for cb in self.cbs: getattr(cb, name, noop)()\n",
    "\n",
    "            \n",
    "\n",
    "import numpy as np\n",
    "from fastai.optimizer import Adam\n",
    "from fastai.basics import progress_bar, CancelFitException\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from fastai.imports import noop\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "class My_Learner_img:\n",
    "    \"\"\"Learner for combined image and tabular data.\"\"\"\n",
    "    \n",
    "    np = __import__('numpy')\n",
    "    from fastai.optimizer import Adam\n",
    "    \n",
    "    def __init__(self, model, dls, loss_func, lr, cbs, opt_func=Adam):\n",
    "        store_attr()\n",
    "        for cb in cbs: cb.learner = self\n",
    "\n",
    "    def one_batch(self):\n",
    "        import torch\n",
    "        self('before_batch')\n",
    "        \n",
    "        if self.model.training:\n",
    "            images = self.batch['image'].float().cuda()\n",
    "            yb = self.batch['label'].cuda()\n",
    "\n",
    "            self.preds = self.model(images)\n",
    "            self.loss = self.loss_func(self.preds, yb)\n",
    "            self.loss.backward()\n",
    "            self.opt.step()\n",
    "        \n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                images = self.batch['image'].float().cuda()\n",
    "                yb = self.batch['label'].cuda()\n",
    "\n",
    "                self.preds = self.model(images)\n",
    "                self.loss = self.loss_func(self.preds, yb)\n",
    "                \n",
    "        acc = (self.preds.argmax(dim=1) == yb).float().sum()\n",
    "        self.accs.append(acc)\n",
    "        n = len(yb)\n",
    "        \n",
    "        self.losses.append(self.loss * n)\n",
    "        self.ns.append(n)\n",
    "        self.y_pred.append(self.preds.argmax(dim=1).cpu())\n",
    "        self.y_true.append(yb.cpu())\n",
    "        self('after_batch')\n",
    "\n",
    "    def one_epoch(self, train):\n",
    "        from fastai.basics import progress_bar\n",
    "        self.model.training = train\n",
    "        self('before_epoch')\n",
    "        self.accs, self.losses, self.ns, self.y_pred, self.y_true = [], [], [], [], []\n",
    "        \n",
    "        dl = self.dls.train if train else self.dls.valid\n",
    "        for self.num, self.batch in enumerate(progress_bar(dl, leave=False)):\n",
    "            self.one_batch()\n",
    "        \n",
    "        n = sum(self.ns)\n",
    "        y_true = torch.cat(self.y_true).numpy()\n",
    "        y_pred = torch.cat(self.y_pred).numpy()\n",
    "        f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "        \n",
    "        phase = \"TRAINING\" if self.model.training else \"VALIDATION\"\n",
    "        print(f'{\"Epoch: \" + str(self.epoch) if self.model.training else \"\"}')\n",
    "        print(f'{phase} Loss: {sum(self.losses).item()/n:.4f}, Accuracy: {sum(self.accs).item()/n:.4f}, F1-score: {f1:.4f}')\n",
    "        \n",
    "        if self.model.training: \n",
    "            self.tr_losses_acc.append(sum(self.losses).item()/n)\n",
    "            self.tr_f1_scores.append(f1)\n",
    "        else: \n",
    "            self.va_losses_acc.append(sum(self.losses).item()/n)\n",
    "            self.va_f1_scores.append(f1)\n",
    "            print('----------------------------------------------------------')\n",
    "        self('after_epoch')\n",
    "    \n",
    "    def fit(self, n_epochs):\n",
    "        from fastai.basics import CancelFitException\n",
    "        from fastai.basics import progress_bar\n",
    "        import torch\n",
    "        self('before_fit')\n",
    "        self.tr_losses_acc, self.va_losses_acc = [], []\n",
    "        self.tr_f1_scores, self.va_f1_scores = [], []\n",
    "        \n",
    "        self.model = self.model.float().cuda()\n",
    "    \n",
    "        self.opt = self.opt_func(self.model.parameters(), self.lr)\n",
    "        self.n_epochs = n_epochs\n",
    "        try:\n",
    "            for self.epoch in progress_bar(range(n_epochs)):\n",
    "                self.one_epoch(True)\n",
    "                self.one_epoch(False)\n",
    "        except CancelFitException: pass\n",
    "        self('after_fit')\n",
    "        \n",
    "    def validate(self):\n",
    "        self.one_epoch(False)\n",
    "        \n",
    "        import matplotlib.pyplot as plt\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        ax1.plot(self.tr_losses_acc, label='Training')\n",
    "        ax1.plot(self.va_losses_acc, label='Validation')\n",
    "        ax1.set_title('Loss')\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.set_yscale('log')\n",
    "        ax1.legend()\n",
    "        \n",
    "        ax2.plot(self.tr_f1_scores, label='Training')\n",
    "        ax2.plot(self.va_f1_scores, label='Validation')\n",
    "        ax2.set_title('F1-score')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_ylabel('F1-score')\n",
    "        ax2.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        self('after_fit')\n",
    "        \n",
    "    def __call__(self, name):\n",
    "        from fastai.imports import noop\n",
    "        for cb in self.cbs: getattr(cb, name, noop)()\n",
    "\n",
    "\n",
    "#Callbacks\n",
    "class GetAttr:\n",
    "    \"\"\"From FastAI: Inherit from this to have all attr accesses in `self._xtra` passed down to `self.default`\"\"\"\n",
    "    _default='default'\n",
    "    def _component_attr_filter(self,k):\n",
    "        if k.startswith('__') or k in ('_xtra',self._default): return False\n",
    "        xtra = getattr(self,'_xtra',None)\n",
    "        return xtra is None or k in xtra\n",
    "    def _dir(self): return [k for k in dir(getattr(self,self._default)) if self._component_attr_filter(k)]\n",
    "    def __getattr__(self,k):\n",
    "        if self._component_attr_filter(k):\n",
    "            attr = getattr(self,self._default,None)\n",
    "            if attr is not None: return getattr(attr,k)\n",
    "        raise AttributeError(k)\n",
    "    def __dir__(self): return custom_dir(self,self._dir())\n",
    "#     def __getstate__(self): return self.__dict__\n",
    "    def __setstate__(self,data): self.__dict__.update(data)\n",
    "\n",
    "class Callback(GetAttr): _default='learner'\n",
    "\n",
    "class OneCycle(Callback):\n",
    "    \"\"\"Install Onecycle-learning rate\"\"\"\n",
    "    def __init__(self, base_lr): self.base_lr = base_lr\n",
    "    def before_fit(self): self.lrs = []\n",
    "\n",
    "    def before_batch(self):\n",
    "        if not self.model.training: return\n",
    "        n = len(self.dls.train)\n",
    "        bn = self.epoch*n + self.num\n",
    "        mn = self.n_epochs*n\n",
    "        pct = bn/mn\n",
    "        pct_start,div_start = 0.25,10\n",
    "        if pct<pct_start:\n",
    "            pct /= pct_start\n",
    "            lr = (1-pct)*self.base_lr/div_start + pct*self.base_lr\n",
    "        else:\n",
    "            pct = (pct-pct_start)/(1-pct_start)\n",
    "            lr = (1-pct)*self.base_lr\n",
    "        self.opt.lr = lr\n",
    "        self.lrs.append(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c0e200-421d-480a-a670-c43f071318b4",
   "metadata": {},
   "source": [
    "#### Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0b9fb1e-2a3b-40a9-98e2-bf84003442ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import RocCurveDisplay, precision_recall_curve, average_precision_score\n",
    "from sklearn.calibration import calibration_curve\n",
    "from fastai.basics import progress_bar\n",
    "from scipy import stats\n",
    "import torchio as tio\n",
    "from sklearn.utils import resample\n",
    "import torch.nn.functional as F\n",
    "from fastprogress.fastprogress import progress_bar\n",
    "\n",
    "def create_combined_plot(cm_disp, y_true, y_pred_proba, class_names, n_classes, download, download_path, dpi, title, fig=None):\n",
    "    if fig is None:\n",
    "        fig = plt.figure(figsize=(8, 18))\n",
    "    \n",
    "    axes = fig.subplots(3, 1)\n",
    "    plt.subplots_adjust(hspace=0.8)  # Adjust vertical space between subplots\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm_disp.plot(ax=axes[0], cmap='Blues', colorbar=False)\n",
    "    for text in cm_disp.text_.ravel():\n",
    "        text.set_fontsize(16)\n",
    "    axes[0].set_title(title, fontsize=20, pad=20, fontweight='bold')\n",
    "    axes[0].set_xlabel(\"Predicted\", fontsize=18)\n",
    "    axes[0].set_ylabel(\"True\", fontsize=18)\n",
    "    axes[0].tick_params(axis='both', labelsize=14)\n",
    "    \n",
    "    # ROC Curve\n",
    "    if n_classes == 2:\n",
    "        plot_binary_roc(y_true, y_pred_proba[:, 1], axes[1], download, download_path, dpi)\n",
    "    else:\n",
    "        plot_multiclass_roc(y_true, y_pred_proba, n_classes, axes[1], download, download_path, dpi)\n",
    "    \n",
    "    # Precision-Recall Curve\n",
    "    if n_classes == 2:\n",
    "        plot_binary_pr(y_true, y_pred_proba[:, 1], axes[2], download, download_path, dpi)\n",
    "    else:\n",
    "        plot_multiclass_pr(y_true, y_pred_proba, n_classes, axes[2], download, download_path, dpi)\n",
    "    \n",
    "    # Set equal aspect ratio for ROC and PR curves\n",
    "    axes[1].set_aspect('equal', adjustable='box')\n",
    "    axes[2].set_aspect('equal', adjustable='box')\n",
    "\n",
    "    axes[1].set_title(' ', fontsize=20, pad=20, fontweight='bold')\n",
    "    \n",
    "    # Ensure all subplots have the same size\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_combined_plot_roc_prc(cm_disp, y_true, y_pred_proba, class_names, n_classes, download, download_path, dpi, title, fig=None):\n",
    "    if fig is None:\n",
    "        fig = plt.figure(figsize=(8, 18))\n",
    "    \n",
    "    axes = fig.subplots(2, 1)\n",
    "    plt.subplots_adjust(hspace=0.8)  # Adjust vertical space between subplots\n",
    "    axes[0].set_title(title, fontsize=20, pad=20, fontweight='bold')\n",
    "\n",
    "    # ROC Curve\n",
    "    if n_classes == 2:\n",
    "        plot_binary_roc(y_true, y_pred_proba[:, 1], axes[0], download, download_path, dpi)\n",
    "    else:\n",
    "        plot_multiclass_roc(y_true, y_pred_proba, n_classes, axes[0], download, download_path, dpi)\n",
    "    \n",
    "    # Precision-Recall Curve\n",
    "    if n_classes == 2:\n",
    "        plot_binary_pr(y_true, y_pred_proba[:, 1], axes[1], download, download_path, dpi)\n",
    "    else:\n",
    "        plot_multiclass_pr(y_true, y_pred_proba, n_classes, axes[1], download, download_path, dpi)\n",
    "    \n",
    "    # Set equal aspect ratio for ROC and PR curves\n",
    "    axes[0].set_aspect('equal', adjustable='box')\n",
    "    axes[1].set_aspect('equal', adjustable='box')\n",
    "\n",
    "    # axes[0].set_title(' ', fontsize=20, pad=20, fontweight='bold')\n",
    "    \n",
    "    # Ensure all subplots have the same size\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def Interp_from_learner(learn, class_names,\n",
    "                        c,\n",
    "                        use_tabular=True,\n",
    "                        download=False, \n",
    "                        download_path='/media/user/Elements/combined_plot.tiff',\n",
    "                        dpi=1200,\n",
    "                        title=None):\n",
    "    \"\"\"Get Class report incl. Sens/Spec/F1, Confusion matrix and ROC from learner\"\"\"\n",
    "    \n",
    "    y_pred, y_pred_proba, y_true = [], [], []\n",
    "    \n",
    "    for num, batch in enumerate(progress_bar(learn.dls.valid, leave=False)):\n",
    "        with torch.no_grad():\n",
    "            images = batch['image'].float().cuda()\n",
    "            if use_tabular:\n",
    "                tabular = batch['tabular'].float().cuda()\n",
    "            yb = batch['label'].cuda()\n",
    "\n",
    "            learn.model = learn.model.float().cuda()\n",
    "            if use_tabular:\n",
    "                preds = learn.model.eval()(images, tabular)\n",
    "            else:\n",
    "                preds = learn.model.eval()(images)\n",
    "\n",
    "            preds_proba = F.softmax(preds, dim=1)\n",
    "            y_pred_proba.append(preds_proba.cpu().numpy())\n",
    "            \n",
    "            y_pred.extend(preds.argmax(dim=1).cpu().numpy().tolist())\n",
    "            y_true.extend(yb.cpu().numpy().tolist())\n",
    "    \n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_pred_proba = np.vstack(y_pred_proba)\n",
    "    \n",
    "    n_classes = y_pred_proba.shape[1]\n",
    "    \n",
    "    # Classification report and Confusion Matrix\n",
    "    class_report = metrics.classification_report(y_true, y_pred)\n",
    "    cm = metrics.confusion_matrix(y_true, y_pred)\n",
    "    cm_disp = metrics.ConfusionMatrixDisplay(cm, display_labels=class_names)\n",
    "    \n",
    "    print('----------------------------------------------------------')\n",
    "    print(class_report)\n",
    "    print('----------------------------------------------------------')\n",
    "    \n",
    "    # Create combined plot\n",
    "    fig = create_combined_plot(cm_disp, y_true, y_pred_proba, class_names, n_classes, download, download_path, dpi, title, fig=None)\n",
    "    \n",
    "    if download:\n",
    "        fig.savefig(download_path, dpi=dpi)\n",
    "    plt.show()\n",
    "    \n",
    "    # Return the figure along with cm_disp, y_true, and y_pred_proba\n",
    "    return fig, cm_disp, y_true, y_pred_proba\n",
    "\n",
    "\n",
    "def plot_binary_roc(y_true, y_pred_proba, ax, download, download_path, dpi):    \n",
    "    n_bootstraps = 1000\n",
    "    rng_seed = 42\n",
    "    bootstrapped_auc = []\n",
    "\n",
    "    rng = np.random.RandomState(rng_seed)\n",
    "    for i in range(n_bootstraps):\n",
    "        indices = rng.randint(0, len(y_true), len(y_true))\n",
    "        y_true_bootstrap = y_true[indices]\n",
    "        y_pred_proba_bootstrap = y_pred_proba[indices]\n",
    "        \n",
    "        fpr, tpr, _ = metrics.roc_curve(y_true_bootstrap, y_pred_proba_bootstrap)\n",
    "        bootstrapped_auc.append(metrics.auc(fpr, tpr))\n",
    "\n",
    "    auc, std_auc = np.mean(bootstrapped_auc), np.std(bootstrapped_auc)\n",
    "\n",
    "    RocCurveDisplay.from_predictions(\n",
    "        y_true, \n",
    "        y_pred_proba, \n",
    "        ax=ax, \n",
    "        color='royalblue',\n",
    "    )\n",
    "\n",
    "    # Plot confidence intervals\n",
    "    tprs = []\n",
    "    base_fpr = np.linspace(0, 1, 101)\n",
    "\n",
    "    for i in range(n_bootstraps):\n",
    "        indices = rng.randint(0, len(y_true), len(y_true))\n",
    "        y_true_bootstrap = y_true[indices]\n",
    "        y_pred_proba_bootstrap = y_pred_proba[indices]\n",
    "        \n",
    "        fpr, tpr, _ = metrics.roc_curve(y_true_bootstrap, y_pred_proba_bootstrap)\n",
    "        tpr = np.interp(base_fpr, fpr, tpr)\n",
    "        tpr[0] = 0.0\n",
    "        tprs.append(tpr)\n",
    "\n",
    "    tprs = np.array(tprs)\n",
    "    mean_tprs = tprs.mean(axis=0)\n",
    "    std_tprs = tprs.std(axis=0)\n",
    "\n",
    "    tprs_upper = np.minimum(mean_tprs + std_tprs, 1)\n",
    "    tprs_lower = mean_tprs - std_tprs\n",
    "\n",
    "    ax.fill_between(base_fpr, tprs_lower, tprs_upper, color='royalblue', alpha=0.3)\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    ax.set_aspect('equal')\n",
    "    ax.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "    \n",
    "    ax.set_xlabel(\"False Positive Rate\", fontsize=18)\n",
    "    ax.set_ylabel(\"True Positive Rate\", fontsize=18)\n",
    "    ax.tick_params(axis='both', labelsize=14)\n",
    "    roc_line = ax.get_lines()[-2]  #get the ROC curve line\n",
    "    ax.legend([roc_line],\n",
    "              [f'AUROC = {auc:.2f} ± {std_auc:.2f})'],\n",
    "              loc=\"lower right\",\n",
    "              prop={'size': 14})\n",
    "\n",
    "def plot_binary_pr(y_true, y_pred_proba, ax, download, download_path, dpi):    \n",
    "    n_bootstraps = 1000\n",
    "    rng_seed = 42\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred_proba)\n",
    "    average_precision = average_precision_score(y_true, y_pred_proba)\n",
    "    \n",
    "    bootstrapped_ap = []\n",
    "    rng = np.random.RandomState(rng_seed)\n",
    "    \n",
    "    for _ in range(n_bootstraps):\n",
    "        indices = rng.randint(0, len(y_true), len(y_true))\n",
    "        y_true_bootstrap = y_true[indices]\n",
    "        y_pred_proba_bootstrap = y_pred_proba[indices]\n",
    "        ap = average_precision_score(y_true_bootstrap, y_pred_proba_bootstrap)\n",
    "        bootstrapped_ap.append(ap)\n",
    "    \n",
    "    ap_std = np.std(bootstrapped_ap)\n",
    "    \n",
    "    ax.plot(recall, precision, color='chocolate', label=f'AUPRC = {average_precision:.2f} ± {ap_std:.2f}')\n",
    "    ax.fill_between(recall, precision - ap_std, precision + ap_std, color='chocolate', alpha=0.3)\n",
    "    ax.set_xlim([-0.01, 1.01])\n",
    "    ax.set_ylim([-0.01, 1.1])  # The upper limit is set to 1.05 to give a little space above the curve\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "    ax.legend(loc='lower left')\n",
    "    ax.set_xlabel(\"Recall\", fontsize=18)\n",
    "    ax.set_ylabel(\"Precision\", fontsize=18)\n",
    "    ax.tick_params(axis='both', labelsize=14)\n",
    "    ax.legend(prop={'size': 14})\n",
    "\n",
    "def delong_roc_variance(ground_truth, predictions):\n",
    "    order = np.lexsort((predictions, ground_truth))\n",
    "    ground_truth = ground_truth[order]\n",
    "    predictions = predictions[order]\n",
    "    \n",
    "    total_pos = np.sum(ground_truth)\n",
    "    total_neg = len(ground_truth) - total_pos\n",
    "    \n",
    "    pos_ranks = np.where(ground_truth == 1)[0] + 1\n",
    "    neg_ranks = np.where(ground_truth == 0)[0] + 1\n",
    "    \n",
    "    pos_ranks_sum = np.sum(pos_ranks)\n",
    "    neg_ranks_sum = np.sum(neg_ranks)\n",
    "    \n",
    "    auc = (pos_ranks_sum - total_pos * (total_pos + 1) / 2) / (total_pos * total_neg)\n",
    "    \n",
    "    v01 = (auc * (1 - auc)) / (total_neg - 1)\n",
    "    v10 = (auc * (1 - auc)) / (total_pos - 1)\n",
    "    \n",
    "    sx = np.zeros(len(ground_truth))\n",
    "    sy = np.zeros(len(ground_truth))\n",
    "    \n",
    "    for i in range(len(ground_truth)):\n",
    "        if ground_truth[i] == 1:\n",
    "            sx[i] = (neg_ranks_sum - total_neg * i) / (total_pos * total_neg)\n",
    "        else:\n",
    "            sy[i] = (pos_ranks_sum - total_pos * (len(ground_truth) - i)) / (total_pos * total_neg)\n",
    "    \n",
    "    var_auc = (np.sum(sx ** 2) * v01 + np.sum(sy ** 2) * v10) / len(ground_truth)\n",
    "    return var_auc\n",
    "\n",
    "def delong_test(ground_truth, predictions_1, predictions_2):\n",
    "    var_auc_1 = delong_roc_variance(ground_truth, predictions_1)\n",
    "    var_auc_2 = delong_roc_variance(ground_truth, predictions_2)\n",
    "    \n",
    "    auc_1 = metrics.roc_auc_score(ground_truth, predictions_1)\n",
    "    auc_2 = metrics.roc_auc_score(ground_truth, predictions_2)\n",
    "    \n",
    "    cov_auc = delong_roc_covariance(ground_truth, predictions_1, predictions_2)\n",
    "    \n",
    "    z = (auc_1 - auc_2) / np.sqrt(var_auc_1 + var_auc_2 - 2 * cov_auc)\n",
    "    p = 2 * (1 - stats.norm.cdf(abs(z)))\n",
    "    \n",
    "    return z, p\n",
    "\n",
    "def delong_roc_covariance(ground_truth, predictions_1, predictions_2):\n",
    "    pos = np.where(ground_truth == 1)[0]\n",
    "    neg = np.where(ground_truth == 0)[0]\n",
    "    \n",
    "    total_pos = len(pos)\n",
    "    total_neg = len(neg)\n",
    "    \n",
    "    pos_ranks_1 = np.argsort(predictions_1)\n",
    "    pos_ranks_2 = np.argsort(predictions_2)\n",
    "    \n",
    "    covariance = 0\n",
    "    for i in range(total_pos):\n",
    "        for j in range(total_neg):\n",
    "            covariance += (\n",
    "                (pos_ranks_1[pos[i]] < pos_ranks_1[neg[j]]) == (pos_ranks_2[pos[i]] < pos_ranks_2[neg[j]])\n",
    "            ) - 0.5\n",
    "    \n",
    "    covariance /= (total_pos * total_neg)\n",
    "    return covariance\n",
    "\n",
    "def Interp_from_two_learners(learners, class_names, c,\n",
    "                             download=False, \n",
    "                             download_path1='/media/user/Elements/ROC_combined.tiff',\n",
    "                             download_path2='/media/user/Elements/PR_combined.tiff',\n",
    "                             dpi=1200):\n",
    "    \"\"\"\n",
    "    Get ROC, PRC, and Brier score from two learners\n",
    "    - Input = expects two different types of learners: first one uses image&tabular data, second one uses only image data,\n",
    "    list of two learners: [learner_img_tab, learner_img]\n",
    "    - class_names = list of class names ['A', 'B',...] -> class 0, 1,...\n",
    "    - c = in_channels\n",
    "    - can download plots if download=True, add paths where to download and put to .tiff\n",
    "    \"\"\"\n",
    "    \n",
    "    results = []\n",
    "    for i, learn in enumerate(learners):\n",
    "        y_pred, y_pred_proba, y_true = [], [], []\n",
    "        \n",
    "        for num, batch in enumerate(progress_bar(learn.dls.valid, leave=False)):\n",
    "            with torch.no_grad():\n",
    "                images = batch['image'].float().cuda()\n",
    "                yb = batch['label'].cuda()\n",
    "\n",
    "                learn.model = learn.model.float().cuda()\n",
    "                if i == 0:  # First learner uses both image and tabular data\n",
    "                    tabular = batch['tabular'].float().cuda()\n",
    "                    preds = learn.model.eval()(images, tabular)\n",
    "                else:  # Second learner uses only image data\n",
    "                    preds = learn.model.eval()(images)\n",
    "                \n",
    "                preds_proba = F.softmax(preds, dim=1) #apply Softmax to get probabilities\n",
    "                y_pred_proba.append(preds_proba.cpu().numpy())\n",
    "                \n",
    "                y_pred.extend(preds.argmax(dim=1).cpu().numpy().tolist())\n",
    "                y_true.extend(yb.cpu().numpy().tolist())\n",
    "        \n",
    "        results.append({\n",
    "            'y_true': np.array(y_true),\n",
    "            'y_pred': np.array(y_pred),\n",
    "            'y_pred_proba': np.vstack(y_pred_proba)\n",
    "        })\n",
    "    \n",
    "    n_classes = results[0]['y_pred_proba'].shape[1]\n",
    "    \n",
    "    if n_classes == 2:\n",
    "        plot_binary_roc_combined(results, download, download_path1, dpi)\n",
    "        plot_binary_pr_combined(results, download, download_path2, dpi)\n",
    "        # plot_binary_brier_combined(results, download, download_path4, dpi)\n",
    "\n",
    "        # Perform DeLong test\n",
    "        y_true = results[0]['y_true']  # Assuming both models have the same ground truth\n",
    "        y_pred_1 = results[0]['y_pred_proba'][:, 1]\n",
    "        y_pred_2 = results[1]['y_pred_proba'][:, 1]\n",
    "        \n",
    "        z, p = delong_test(y_true, y_pred_1, y_pred_2)\n",
    "        print(f\"DeLong test results:\")\n",
    "        print(f\"p-value: {p:.4f}\")\n",
    "        \n",
    "def plot_binary_roc_combined(results, download, download_path, dpi, n_bootstraps=1000, confidence_level=0.95):\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    colors = ['royalblue', 'darkorange']\n",
    "    labels = ['Image+Tabular', 'Image Only']\n",
    "    \n",
    "    for i, (result, color, label) in enumerate(zip(results, colors, labels)):\n",
    "        y_true, y_pred_proba = result['y_true'], result['y_pred_proba'][:, 1]\n",
    "        \n",
    "        # Calculate the original ROC curve\n",
    "        fpr, tpr, _ = metrics.roc_curve(y_true, y_pred_proba)\n",
    "        roc_auc = metrics.auc(fpr, tpr)\n",
    "        \n",
    "        # Bootstrap to calculate confidence intervals\n",
    "        tprs = []\n",
    "        aucs = []\n",
    "        mean_fpr = np.linspace(0, 1, 100)\n",
    "        \n",
    "        for _ in range(n_bootstraps):\n",
    "            # Resample with replacement\n",
    "            indices = resample(range(len(y_true)), n_samples=len(y_true))\n",
    "            y_true_boot = y_true[indices]\n",
    "            y_pred_proba_boot = y_pred_proba[indices]\n",
    "            \n",
    "            # Calculate ROC curve for the bootstrap sample\n",
    "            fpr_boot, tpr_boot, _ = metrics.roc_curve(y_true_boot, y_pred_proba_boot)\n",
    "            tprs.append(np.interp(mean_fpr, fpr_boot, tpr_boot))\n",
    "            aucs.append(metrics.auc(fpr_boot, tpr_boot))\n",
    "        \n",
    "        # Calculate confidence intervals\n",
    "        tprs = np.array(tprs)\n",
    "        mean_tpr = np.mean(tprs, axis=0)\n",
    "        std_tpr = np.std(tprs, axis=0)\n",
    "        \n",
    "        tprs_upper = np.minimum(mean_tpr + stats.norm.ppf((1 + confidence_level) / 2) * std_tpr, 1)\n",
    "        tprs_lower = np.maximum(mean_tpr - stats.norm.ppf((1 + confidence_level) / 2) * std_tpr, 0)\n",
    "        \n",
    "        # Plot ROC curve with confidence interval\n",
    "        ax.plot(fpr, tpr, color=color, lw=2, label=f'{label} (AUC = {roc_auc:.2f})')\n",
    "        ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color=color, alpha=0.3,\n",
    "                        label=f'{confidence_level*100:.0f}% CI')\n",
    "    \n",
    "    ax.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    plt.xlabel(\"False Positive Rate\", fontsize=12)\n",
    "    plt.ylabel(\"True Positive Rate\", fontsize=12)\n",
    "    \n",
    "    # Add DeLong test results to the plot\n",
    "    y_true = results[0]['y_true']\n",
    "    y_pred_1 = results[0]['y_pred_proba'][:, 1]\n",
    "    y_pred_2 = results[1]['y_pred_proba'][:, 1]\n",
    "    z, p = delong_test(y_true, y_pred_1, y_pred_2)\n",
    "    ax.text(0.75, 0.25, f\"DeLong test:\\np = {p:.4f}\", \n",
    "            transform=ax.transAxes, fontsize=10, \n",
    "           )\n",
    "    \n",
    "    if download:\n",
    "        plt.savefig(download_path, dpi=dpi)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_binary_pr_combined(results, download, download_path, dpi, n_bootstraps=1000, confidence_level=0.95):\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    colors = ['chocolate', 'forestgreen']\n",
    "    labels = ['Image+Tabular', 'Image Only']\n",
    "    \n",
    "    for i, (result, color, label) in enumerate(zip(results, colors, labels)):\n",
    "        y_true, y_pred_proba = result['y_true'], result['y_pred_proba'][:, 1]\n",
    "        \n",
    "        # Calculate the original PR curve\n",
    "        precision, recall, _ = precision_recall_curve(y_true, y_pred_proba)\n",
    "        average_precision = average_precision_score(y_true, y_pred_proba)\n",
    "        \n",
    "        # Bootstrap to calculate confidence intervals\n",
    "        precisions = []\n",
    "        avg_precisions = []\n",
    "        mean_recall = np.linspace(0, 1, 100)\n",
    "        \n",
    "        for _ in range(n_bootstraps):\n",
    "            # Resample with replacement\n",
    "            indices = resample(range(len(y_true)), n_samples=len(y_true))\n",
    "            y_true_boot = y_true[indices]\n",
    "            y_pred_proba_boot = y_pred_proba[indices]\n",
    "            \n",
    "            # Calculate PR curve for the bootstrap sample\n",
    "            precision_boot, recall_boot, _ = precision_recall_curve(y_true_boot, y_pred_proba_boot)\n",
    "            precisions.append(np.interp(mean_recall, recall_boot[::-1], precision_boot[::-1]))\n",
    "            avg_precisions.append(average_precision_score(y_true_boot, y_pred_proba_boot))\n",
    "        \n",
    "        # Calculate confidence intervals\n",
    "        precisions = np.array(precisions)\n",
    "        mean_precision = np.mean(precisions, axis=0)\n",
    "        std_precision = np.std(precisions, axis=0)\n",
    "        \n",
    "        precisions_upper = np.minimum(mean_precision + stats.norm.ppf((1 + confidence_level) / 2) * std_precision, 1)\n",
    "        precisions_lower = np.maximum(mean_precision - stats.norm.ppf((1 + confidence_level) / 2) * std_precision, 0)\n",
    "        \n",
    "        # Plot PR curve with confidence interval\n",
    "        ax.plot(recall, precision, color=color, lw=2, label=f'{label} (AP = {average_precision:.2f})')\n",
    "        ax.fill_between(mean_recall, precisions_lower, precisions_upper, color=color, alpha=0.3,\n",
    "                        label=f'{confidence_level*100:.0f}% CI')\n",
    "    \n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.legend(loc=\"lower left\")\n",
    "    plt.xlabel(\"Recall\", fontsize=12)\n",
    "    plt.ylabel(\"Precision\", fontsize=12)\n",
    "    \n",
    "    if download:\n",
    "        plt.savefig(download_path, dpi=dpi)\n",
    "    plt.show()\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "class CustomModelWrapper:\n",
    "    def __init__(self, model, images):\n",
    "        self.model = model\n",
    "        self.images = images\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, X_tab):\n",
    "        X_tab = torch.tensor(X_tab, dtype=torch.float32).to(next(self.model.parameters()).device)\n",
    "        images = self.images.to(next(self.model.parameters()).device)\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(images, X_tab)\n",
    "        return preds.cpu().numpy()\n",
    "\n",
    "def custom_scorer(estimator, X, y):\n",
    "    y_pred = estimator.predict_proba(X)\n",
    "    return -log_loss(y, y_pred)\n",
    "\n",
    "def get_tabular_importance(model, dataloader, n_repeats=10):\n",
    "    model.eval()\n",
    "    \n",
    "    all_X_tab = []\n",
    "    all_y = []\n",
    "    all_images = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            all_X_tab.append(batch['tabular'])\n",
    "            all_y.append(batch['label'])\n",
    "            all_images.append(batch['image'])\n",
    "    \n",
    "    X_tab = torch.cat(all_X_tab, dim=0)\n",
    "    y = torch.cat(all_y, dim=0)\n",
    "    images = torch.cat(all_images, dim=0)\n",
    "    \n",
    "    wrapped_model = CustomModelWrapper(model, images)\n",
    "    \n",
    "    perm_importance = permutation_importance(\n",
    "        wrapped_model,\n",
    "        X_tab.cpu().numpy(),\n",
    "        y.cpu().numpy(),\n",
    "        n_repeats=n_repeats,\n",
    "        random_state=42,\n",
    "        scoring=custom_scorer\n",
    "    )\n",
    "    \n",
    "    return perm_importance.importances_mean\n",
    "\n",
    "def plot_feature_importances(importances, feature_names=None):\n",
    "    \"\"\"\n",
    "    Visualize feature importances without confidence intervals.\n",
    "    \n",
    "    Parameters:\n",
    "    - importances: array of importance scores\n",
    "    - feature_names: list of feature names (optional)\n",
    "    \"\"\"\n",
    "    # Sort features by importance\n",
    "    sorted_idx = importances.argsort()#[::1]\n",
    "    importances = importances[sorted_idx]\n",
    "    \n",
    "    if feature_names is None:\n",
    "        feature_names = [f\"Feature {i}\" for i in range(len(importances))]\n",
    "    else:\n",
    "        feature_names = [feature_names[i] for i in sorted_idx]\n",
    "    \n",
    "    y_pos = np.arange(len(feature_names))\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12.5, 8))\n",
    "    \n",
    "    # Plot horizontal bars\n",
    "    ax.barh(y_pos, importances, align='center', alpha=0.8)\n",
    "    \n",
    "    # Customize the plot\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(feature_names)\n",
    "    ax.set_xlabel('Feature Importance')\n",
    "    ax.set_title('Feature Importances')\n",
    "    \n",
    "    # Add importance values at the end of each bar\n",
    "    for i, v in enumerate(importances):\n",
    "        ax.text(v, i, f' {v:.3f}', va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def Wrong_instances(learn, c, use_tabular=True, display=True):\n",
    "    \"\"\"Get wrongly predicted instances incl. Accessionnumber (has to be defined in subject)\n",
    "    learner\n",
    "    c=channels_in\"\"\"\n",
    "    \n",
    "    predictions = []\n",
    "    nihss = []\n",
    "    \n",
    "    for num,batch in enumerate(progress_bar(learn.dls.valid, leave=False)):\n",
    "        with torch.no_grad():\n",
    "            images = batch['image'].float().cuda()\n",
    "            yb = batch['label'].cuda()\n",
    "            if use_tabular:\n",
    "                tabular = batch['tabular'].float().cuda()\n",
    "            y_nihss = batch['nihss'].float()\n",
    "            acc_num = batch['acc']\n",
    "\n",
    "            learn.model = learn.model.float().cuda()\n",
    "            if use_tabular:\n",
    "                preds = learn.model.eval()(images, tabular)\n",
    "            else:\n",
    "                preds = learn.model.eval()(images)\n",
    "            \n",
    "            # Calculate softmax probabilities\n",
    "            probs = F.softmax(preds, dim=1)\n",
    "            \n",
    "            for i in range(len(yb)):\n",
    "                if preds.argmax(dim=1)[i] != yb[i]:\n",
    "                    pred_class = preds.argmax(dim=1)[i]\n",
    "                    pred_prob = probs[i][pred_class].item() * 100  # Convert to percentage\n",
    "                    \n",
    "                    if display:\n",
    "                        print(f'Batch: {num}, Prediction: {pred_class} (Probability: {pred_prob:.2f}%), '\n",
    "                              f'True NIHSS: {int(y_nihss[i])}, Accessionnumber: {int(acc_num[i])}')\n",
    "                    \n",
    "                    predictions.append(int(pred_class))\n",
    "                    nihss.append(int(y_nihss[i]))\n",
    "\n",
    "def Correct_instances(learn, c, use_tabular=True, display=True):\n",
    "    \"\"\"Get wrongly predicted instances incl. Accessionnumber (has to be defined in subject)\n",
    "    learner\n",
    "    c=channels_in\"\"\"\n",
    "    \n",
    "    predictions = []\n",
    "    nihss = []\n",
    "    \n",
    "    for num,batch in enumerate(progress_bar(learn.dls.valid, leave=False)):\n",
    "        with torch.no_grad():\n",
    "            images = batch['image'].float().cuda()\n",
    "            yb = batch['label'].cuda()\n",
    "            if use_tabular:\n",
    "                tabular = batch['tabular'].float().cuda()\n",
    "            y_nihss = batch['nihss'].float()\n",
    "            acc_num = batch['acc']\n",
    "\n",
    "            learn.model = learn.model.float().cuda()\n",
    "            if use_tabular:\n",
    "                preds = learn.model.eval()(images, tabular)\n",
    "            else:\n",
    "                preds = learn.model.eval()(images)\n",
    "            \n",
    "            # Calculate softmax probabilities\n",
    "            probs = F.softmax(preds, dim=1)\n",
    "            \n",
    "            for i in range(len(yb)):\n",
    "                if preds.argmax(dim=1)[i] == yb[i]:\n",
    "                    pred_class = preds.argmax(dim=1)[i]\n",
    "                    pred_prob = probs[i][pred_class].item() * 100  # Convert to percentage\n",
    "                    \n",
    "                    if display:\n",
    "                        print(f'Batch: {num}, Prediction: {pred_class} (Probability: {pred_prob:.2f}%), '\n",
    "                              f'True NIHSS: {int(y_nihss[i])}, Accessionnumber: {int(acc_num[i])}')\n",
    "                    \n",
    "                    predictions.append(int(pred_class))\n",
    "                    nihss.append(int(y_nihss[i]))\n",
    "\n",
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        \n",
    "        self.target_layer.register_forward_hook(self.save_activation)\n",
    "        self.target_layer.register_backward_hook(self.save_gradient)\n",
    "    \n",
    "    def save_activation(self, module, input, output):\n",
    "        self.activations = output.detach()\n",
    "    \n",
    "    def save_gradient(self, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output[0].detach()\n",
    "    \n",
    "    def generate_cam(self, input_image, tabular_data=None, target_class=1):\n",
    "        from scipy.ndimage import zoom\n",
    "        \n",
    "        self.model.eval()\n",
    "        \n",
    "        #Ensure input_image is 5D: [batch, channels, depth, height, width]\n",
    "        if input_image.dim() == 4:\n",
    "            input_image = input_image.unsqueeze(0)  #Add batch dimension if not present\n",
    "\n",
    "        if tabular_data is not None:\n",
    "            tabular_data = tabular_data.to(dtype=torch.float32)\n",
    "            output = self.model(input_image, tabular_data)\n",
    "        else:\n",
    "            output = self.model(input_image)\n",
    "        \n",
    "        self.model.zero_grad()\n",
    "        output[:, target_class].backward()\n",
    "        \n",
    "        if self.gradients is None or self.activations is None:\n",
    "            print(\"Warning: gradients or activations are None\")\n",
    "            return None\n",
    "\n",
    "        pooled_gradients = torch.mean(self.gradients, dim=[0, 2, 3, 4])\n",
    "        for i in range(self.activations.shape[1]):\n",
    "            self.activations[:, i, :, :, :] *= pooled_gradients[i]\n",
    "        \n",
    "        heatmap = torch.mean(self.activations, dim=1).squeeze().cpu().numpy()\n",
    "        heatmap = np.maximum(heatmap, 0)\n",
    "        heatmap /= np.max(heatmap)\n",
    "        \n",
    "        #Resize heatmap to match input image dimensions\n",
    "        zoom_factors = (input_image.shape[2] / heatmap.shape[0],\n",
    "                        input_image.shape[3] / heatmap.shape[1],\n",
    "                        input_image.shape[4] / heatmap.shape[2])\n",
    "        heatmap = zoom(heatmap, zoom_factors)\n",
    "        \n",
    "        return heatmap\n",
    "    \n",
    "    def plot_cam(self, input_image, tabular_data=None, download=False, sl=-1, target_class=1,\n",
    "                 alpha=0.5,\n",
    "                 norm=None,\n",
    "                 download_path='/media/user/Elements/GradCAM.tiff',\n",
    "                 dpi=300):\n",
    "        import matplotlib.pyplot as plt\n",
    "        import matplotlib.colors as mcolors\n",
    "        \n",
    "        heatmap = self.generate_cam(input_image, tabular_data, target_class=target_class)\n",
    "\n",
    "        if sl==-1:\n",
    "            sl=heatmap.shape[2]//2\n",
    "        else:\n",
    "            sl=sl\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "\n",
    "        # norm = mcolors.Normalize(vmin=0, vmax=1, clip=False)\n",
    "        plt.imshow(input_image.cpu().numpy()[0,:,:,sl], cmap='viridis', norm=norm)\n",
    "        plt.title('Original Image')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(input_image.cpu().numpy()[0,:,:,sl], cmap='viridis', norm=norm, alpha=1)\n",
    "        plt.imshow(heatmap[:,:,sl], cmap='jet', alpha=alpha)\n",
    "        plt.title('Grad-CAM')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        if download:\n",
    "            plt.savefig(download_path, dpi=dpi)\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668fde3a-e816-4ea6-8b45-7a25f50cba31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
