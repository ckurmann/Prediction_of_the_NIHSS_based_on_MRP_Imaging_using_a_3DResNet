{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79754346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import nibabel as nib\n",
    "import torchio as tio\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from fastai.vision.all import *\n",
    "\n",
    "import import_ipynb\n",
    "import Utils as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4b37bc-217f-40b4-988f-1e2e3a835b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5803b31c",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bb3264-79ae-4546-8f80-4534278d023c",
   "metadata": {},
   "source": [
    "##### Load df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10010012-e425-4b6c-b75f-164cd2e9a48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('/df_tr_val_test.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6a6c57-dda0-4773-834a-b521c55cf524",
   "metadata": {},
   "source": [
    "##### Split training/validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc63bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df['train_val_test']=='train']\n",
    "\n",
    "df_valid = df[df['train_val_test']=='valid']\n",
    "df_valid = df_valid.reset_index(drop=True)\n",
    "\n",
    "df_test = df[df['train_val_test']=='test']\n",
    "df_test = df_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ef6cde",
   "metadata": {},
   "source": [
    "### Create Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134b5660",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_train = [tio.Subject(perf1=tio.ScalarImage(df_train['tmax_paths'][i]),\n",
    "                              target=(df_train['target_bin'][i]),\n",
    "                              nihss=df_train['NIH on admission'][i],\n",
    "                              acc=df_train['AccessNumber'][i]) \n",
    "                  for i in tqdm(range(len(df_train)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72692e7-40f1-4235-8b1a-40a69c5f3f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_valid = [tio.Subject(perf1=tio.ScalarImage(df_valid['tmax_paths'][i]),\n",
    "                              target=(df_valid['target_bin'][i]),\n",
    "                              nihss=df_valid['NIH on admission'][i],\n",
    "                              acc=df_valid['AccessNumber'][i]) \n",
    "                  for i in tqdm(range(len(df_valid)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42eaef74",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_test = [tio.Subject(perf1=tio.ScalarImage(df_test['tmax_paths'][i]),\n",
    "                             target=(df_test['target_bin'][i]),\n",
    "                             nihss=df_test['NIH on admission'][i],\n",
    "                             acc=df_test['AccessNumber'][i]) \n",
    "                 for i in tqdm(range(len(df_test)))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce58d40b",
   "metadata": {},
   "source": [
    "### Preprocess (perform all static preprocessing steps before training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d56e6b6-aed1-4d0f-8043-7214530bf045",
   "metadata": {},
   "source": [
    "##### Define target size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1d1bd8-1de0-4a95-8f27-5486ef6752ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (70,84,18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32de552f-539b-440a-9a32-35b0e97f4fda",
   "metadata": {},
   "source": [
    "##### Preprocess images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f965cc-6035-4f7c-9b81-f351a9456d6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_fail=[]\n",
    "for i in tqdm(range(len(subjects_train)), desc='Preprocess training subjects'):\n",
    "    try:\n",
    "        subjects_train[i] = u.preprocess(subjects_train[i], target_size)\n",
    "    except:\n",
    "        train_fail.append(i)\n",
    "\n",
    "if train_fail == []:\n",
    "    print(\"All preprocessed successfully\")\n",
    "else:\n",
    "    print(f\"Index of failed preprocessing in training subjects: {train_fail}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431811aa-bf53-492e-b8d8-6ae69b645789",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_fail=[]\n",
    "for i in tqdm(range(len(subjects_valid)), desc='Preprocess training subjects'):\n",
    "    try:\n",
    "        subjects_valid[i] = u.preprocess(subjects_valid[i], target_size)\n",
    "    except:\n",
    "        valid_fail.append(i)\n",
    "\n",
    "if valid_fail == []:\n",
    "    print(\"All preprocessed successfully\")\n",
    "else:\n",
    "    print(f\"Index of failed preprocessing in training subjects: {valid_fail}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34abc5fe-2045-4117-8d15-219a9648dba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fail=[]\n",
    "for i in tqdm(range(len(subjects_test)), desc='Preprocess test subjects'):\n",
    "    try:\n",
    "        subjects_test[i] = u.preprocess(subjects_test[i], target_size)\n",
    "    except:\n",
    "        test_fail.append(i)\n",
    "\n",
    "if test_fail == []:\n",
    "    print(\"All preprocessed successfully\")\n",
    "else:\n",
    "    print(f\"Index of failed preprocessing in test subjects: {test_fail}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3a464b-bfa4-4acd-8aaa-7230b6c5968d",
   "metadata": {},
   "source": [
    "##### Visual checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e819f040",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = random.randint(0,len(subjects_train))\n",
    "\n",
    "print(f'Subject: {s}')\n",
    "perfs = ['perf1']\n",
    "titles = ['TMAX']\n",
    "\n",
    "print(f'Shape: {subjects_train[s]['perf1'].data.shape}')\n",
    "\n",
    "for perf, title in zip(perfs, titles):\n",
    "    plt.imshow(subjects_train[s][perf][tio.DATA][0,:,:,7])\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b56e34",
   "metadata": {},
   "source": [
    "### Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54076c2-19f1-471c-8cbb-1cf89dba713d",
   "metadata": {},
   "source": [
    "##### Define Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197b1ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,z=subjects_train[0]['perf1'].shape[1], subjects_train[0]['perf1'].shape[2], subjects_train[0]['perf1'].shape[3]\n",
    "\n",
    "train_tf = tio.Compose([tio.RandomBlur(std=1,p=0.5), \n",
    "                        tio.RandomNoise(mean=0, std=(0,0.05),p=0.3), \n",
    "                        tio.RandomGhosting(p=0.3), \n",
    "                        tio.RandomSwap(patch_size=(round(x/10),round(y/10),round(z/10)),num_iterations=20,p=0.5), \n",
    "                       ])\n",
    "\n",
    "valid_tf = tio.Compose([])\n",
    "test_tf = tio.Compose([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e75b059-2d5b-4786-965a-e18977241949",
   "metadata": {},
   "source": [
    "##### Visual check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90268abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = subjects_train[random.randint(0, 789)]['perf1'][tio.DATA]\n",
    "plt.imshow(img[0,:,:,10])\n",
    "plt.title('Original example')\n",
    "plt.show()\n",
    "print(f'Original shape: {img.shape[1]}x{img.shape[2]}x{img.shape[3]}')\n",
    "\n",
    "img_t = train_tf(img)\n",
    "plt.imshow(img_t[0,:,:,10])\n",
    "plt.title('Training example')\n",
    "plt.show()\n",
    "print(f'Shape after train_transforms: {img_t.shape[1]}x{img_t.shape[2]}x{img_t.shape[3]}')\n",
    "\n",
    "img_v = valid_tf(img)\n",
    "plt.imshow(img_v[0,:,:,10])\n",
    "plt.title('Validation example')\n",
    "plt.show()\n",
    "print(f'Shape after valid_transforms: {img_v.shape[1]}x{img_v.shape[2]}x{img_v.shape[3]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef89d531",
   "metadata": {},
   "source": [
    "### Dataset/Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b25b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bn=2\n",
    "valid_bn=2\n",
    "test_bn=2\n",
    "\n",
    "dls = u.make_dls(subjects_train, subjects_valid, train_tf, valid_tf, train_bn=train_bn, valid_bn=valid_bn)\n",
    "print(f'Training set: n={len(dls.train.dataset)} ({len(dls.train.dataset)/len(df):.1%})')\n",
    "print(f'Validation set: n={len(dls.valid.dataset)} ({len(dls.valid.dataset)/len(df):.1%})')\n",
    "\n",
    "dls_test = u.make_dls(subjects_test, subjects_test, test_tf, valid_tf, train_bn=valid_bn, valid_bn=valid_bn)\n",
    "print(f'Test set: n={len(dls_test.valid.dataset)} ({len(dls_test.valid.dataset)/len(df):.1%})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7030b663",
   "metadata": {},
   "source": [
    "### Load parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fec6ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = dls.train.dataset[0]['image'].shape[0]\n",
    "num_classes = 2\n",
    "\n",
    "model_resnet = u.ResNet3D18(num_classes=num_classes,\n",
    "                            in_channels=in_channels)\n",
    "\n",
    "loss_func = CrossEntropyLossFlat()\n",
    "lr = 5e-6\n",
    "opt_func = Adam\n",
    "\n",
    "onecyc = u.OneCycle(lr)\n",
    "cbs = [onecyc]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9add0bef-b464-4771-a7a4-f24adbaf787b",
   "metadata": {},
   "source": [
    "### Set up Learners and fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d6d13a-e67b-4591-9571-55ac7469acce",
   "metadata": {},
   "source": [
    "#### Fit Learner: Image only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b664a864-5704-4d60-8d68-18bc57f6d447",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_img = u.My_Learner_img(model_resnet, dls, loss_func=loss_func, lr=lr, cbs=cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b30be3-909e-48b9-99b5-0c556dc90d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_img.fit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460e1a1f-2ec0-4190-8d87-0b29965faf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_img.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8dbace-2b70-42f5-9887-b6856e713298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(learner_img.model.state_dict(), '/media/user/Elements/BENIGN_Results_MRP_nih_dich/MRP_25_04_24_kai/weights_resnet18.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b0a2df-5157-4438-9d9f-cdb57682ab2b",
   "metadata": {},
   "source": [
    "### Interprete learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2efd933",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [f\"NIHSS 0-{cutoff}\", f\"NIHSS >{cutoff}\"]\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95440755-74d5-465e-b177-c5c90f9f27a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner_img.model.load_state_dict(torch.load('/media/user/Elements/BENIGN_Results_MRP_nih_dich/MRP_25_04_24_kai/weights_resnet18.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02a0977",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_plot, val_cm_disp, val_y_true, val_y_pred_proba = u.Interp_from_learner(learner_img, c=in_channels, class_names=class_names, \n",
    "                                                              use_tabular=False,\n",
    "                                                              download=False, \n",
    "                                                              download_path='/media/user/Elements/combined_plot_val.png',\n",
    "                                                              dpi=300,\n",
    "                                                              title='Validation set'\n",
    "                                                             )                               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9676f1a6",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70669935",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_img.dls = dls_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e387191-7948-4c65-aee7-04077ba9099c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_plot, tst_cm_disp, tst_y_true, tst_y_pred_proba = u.Interp_from_learner(learner_img, c=in_channels, class_names=class_names, \n",
    "                                                              use_tabular=False,\n",
    "                                                              download=False, \n",
    "                                                              download_path='/media/user/Elements/BENIGN_Results_MRP_nih_dich/MRP_25_04_24_kai/plot_test_voc_only.tiff',\n",
    "                                                              dpi=900,\n",
    "                                                              title='Test set'\n",
    "                                                             )     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ce4d97-e4bd-4844-8fda-e1e664013d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine plots 3x2\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "gs = gridspec.GridSpec(1, 3, figure=fig)\n",
    "plt.axis('off')\n",
    "\n",
    "# Add line at 1/3 of figure width\n",
    "line = mlines.Line2D([0.325, 0.325], [0.1, 0.91], color='grey', linestyle=':', linewidth=2, transform=fig.transFigure)\n",
    "fig.add_artist(line)\n",
    "line = mlines.Line2D([0.66, 0.66], [0.1, 0.91], color='grey', linestyle=':', linewidth=2, transform=fig.transFigure)\n",
    "fig.add_artist(line)\n",
    "\n",
    "subfig1 = fig.add_subfigure(gs[0, 0])\n",
    "subfig2 = fig.add_subfigure(gs[0, 1])\n",
    "subfig3 = fig.add_subfigure(gs[0, 2])\n",
    "\n",
    "u.create_combined_plot_roc_prc(val_cm_disp, val_y_true, val_y_pred_proba, class_names, n_classes=2, download=False, \n",
    "                     download_path='combined_plot_test.tiff', dpi=900,\n",
    "                     title='Validation set', fig=subfig1)\n",
    "u.create_combined_plot_roc_prc(tst_cm_disp, tst_y_true, tst_y_pred_proba, class_names, n_classes=2, download=False, \n",
    "                     download_path='combined_plot_test.tiff', dpi=900, \n",
    "                     title='Test set', fig=subfig2)\n",
    "u.create_combined_plot_roc_prc(tst_cm_disp_voc, tst_y_true_voc, tst_y_pred_proba_voc, class_names, n_classes=2, download=False, \n",
    "                     download_path='combined_plot_test.tiff', dpi=900, \n",
    "                     title='Test set (only vessel occlusions)', fig=subfig3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.2)\n",
    "# plt.savefig('combined_all_plot_test.tiff', dpi=900)\n",
    "# plt.savefig('combined_all_plot_test.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdbe9b4-daa9-4f55-8cc2-e24c63235f42",
   "metadata": {},
   "source": [
    "#### Analysis of wrongly classified instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd28a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "u.Wrong_instances(learner_img, c=in_channels, use_tabular=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64a5b2f-4c6c-487e-92dd-21be48de7166",
   "metadata": {},
   "source": [
    "##### GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17232a8-2f1f-491d-a050-25c925e7aba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = learner_img.model\n",
    "model.eval()\n",
    "\n",
    "target_layer = model.resnet.layer4[-1]  # Last layer of ResNet3D18\n",
    "\n",
    "input_image = dls_test.valid.dataset[i]['image'].cuda()\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "norm = mcolors.Normalize(vmin=3.5, vmax=7, clip=True)\n",
    "\n",
    "grad_cam = u.GradCAM(model, target_layer)\n",
    "grad_cam.plot_cam(input_image, tabular_data=None, norm=norm, \n",
    "                  download=True, \n",
    "                  target_class=1, \n",
    "                  sl=9,\n",
    "                  alpha = 0.6,\n",
    "                 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
